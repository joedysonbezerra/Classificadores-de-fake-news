{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tcc-dataset-english-cloud.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tUgJZ6erhQoL",
        "xP0xfdGJhgnf"
      ],
      "machine_shape": "hm",
      "mount_file_id": "1oJ27INEFdP-u4fo2HU4j1d4UWUdw1KeC",
      "authorship_tag": "ABX9TyMSynr8pHV5gTahUBAR6BxN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joedysonbezerra/classificadores-de-fake-news/blob/main/tcc_dataset_english_cloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7QCAw4q-nej"
      },
      "source": [
        "## **Bibliotecas necessárias**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tvrupl_mKpD"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUgJZ6erhQoL"
      },
      "source": [
        "# Criando a base de dados com notícias fake\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTbYnoV_sS8G",
        "outputId": "5da91c9d-d0ce-42d9-a89d-a067f86136ea"
      },
      "source": [
        "news_fake_1 = pd.read_csv(\"/content/drive/MyDrive/tcc-dataset/fake.csv\")\n",
        "\n",
        "\n",
        "news_fake_1 = news_fake_1.drop(columns=['date','subject'])\n",
        "\n",
        "\n",
        "\n",
        "news_fake_2 = pd.read_csv(\"/content/drive/MyDrive/tcc-dataset/fake2.csv\")\n",
        "df_remove = news_fake_2.loc[news_fake_2['language'] != 'english']\n",
        "\n",
        "news_fake_2 = news_fake_2.drop(df_remove.index)\n",
        "\n",
        "news_fake_2 = news_fake_2.drop(columns=['uuid' , 'ord_in_thread','author','published','language','crawled','site_url','country','domain_rank','thread_title','spam_score','main_img_url','replies_count','participants_count','likes','comments','shares','type'])\n",
        "\n",
        "news_fake_3 = pd.read_csv(\"/content/drive/MyDrive/tcc-dataset/fake3.csv\")\n",
        "\n",
        "news_fake_3 = news_fake_3.drop(columns=['Unnamed: 0','id' , 'domain','type','url','scraped_at','inserted_at','updated_at','authors','keywords','meta_keywords','meta_description','tags','summary','source'])\n",
        "news_fake_3 = news_fake_3.rename(columns={'content': 'text'})\n",
        "\n",
        "news_fake = news_fake_1 .append(news_fake_2).append(news_fake_3)\n",
        "news_fake['label'] = 0\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP0xfdGJhgnf"
      },
      "source": [
        "# Criando a base de dados com notícias reais\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyCGNCr6fBhC"
      },
      "source": [
        "news_true_1 = pd.read_csv(\"/content/drive/MyDrive/tcc-dataset/true.csv\")\n",
        "news_true_1 = news_true_1.drop(columns=['date','subject'])\n",
        "\n",
        "news_true_2 = pd.read_csv(\"/content/drive/MyDrive/tcc-dataset/true2.csv\")\n",
        "news_true_2 = news_true_2.drop(columns=['Unnamed: 0','id','publication','author','date','year','month','url'])\n",
        "news_true_2 = news_true_2.rename(columns={'content': 'text'})\n",
        "\n",
        "news_true_3 = pd.read_csv(\"/content/drive/MyDrive/tcc-dataset/true3.csv\")\n",
        "news_true_3 = news_true_3.drop(columns=['Unnamed: 0','id','publication','author','date','year','month','url'])\n",
        "news_true_3 = news_true_3.rename(columns={'content': 'text'})\n",
        "\n",
        "\n",
        "news_true_4 = pd.read_csv(\"/content/drive/MyDrive/tcc-dataset/true4.csv\")\n",
        "news_true_4 = news_true_4.drop(columns=['Unnamed: 0','id','publication','author','date','year','month','url'])\n",
        "news_true_4 = news_true_4.rename(columns={'content': 'text'})\n",
        "\n",
        "\n",
        "news_true = news_true_1.append(news_true_2).append(news_true_3).append(news_true_4)\n",
        "news_true['label'] = 1\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc6t3ni_okI9"
      },
      "source": [
        "# Criando uma Base de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTrzeBJouooP",
        "outputId": "5776e636-6385-4496-8e1b-c365a64fe3e8"
      },
      "source": [
        "news = news_true.append(news_fake)\n",
        "news = news.dropna() \n",
        "news = news.sample(frac=0.1)\n",
        "\n",
        "news.groupby('label').label.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    45937\n",
              "1    16268\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqYWs4VxiAih"
      },
      "source": [
        "# **Processando**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehuqTmcoTWIM"
      },
      "source": [
        "## **TF-IDF - Com Tratamento**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsOiWhIUTjXZ"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "config_tfidf = TfidfVectorizer(stop_words='english',\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    token_pattern=r'\\w{2,}',  #vectorize 2-character words or more\n",
        "    ngram_range=(1, 2),lowercase=True, max_features=10000)\n",
        "\n",
        "tfidf = config_tfidf.fit_transform(news.text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4JbJ1no-gyq"
      },
      "source": [
        "\n",
        "## **Separação da base de teste e treino**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERkP-5puz5pN"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(tfidf, news.label, test_size=0.2,random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPSzu19lAg_t"
      },
      "source": [
        "## **Matriz de confusão - Plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kncDFoEQ_gIE"
      },
      "source": [
        "def confusion_matrix_plot(cf_matrix):\n",
        "  group_names = ['Verdadeiro Negativo','Falso Positivo','Falso Negativo','Verdadeiro Positivo']\n",
        "\n",
        "  group_counts = [\"{0:0.0f}\".format(value) for value in\n",
        "                  cf_matrix.flatten()]\n",
        "\n",
        "  labels_confusion_matrix = [f\"{v1}\\n{v2}\" for v1, v2 in\n",
        "            zip(group_names,group_counts)]\n",
        "  labels_confusion_matrix = np.asarray(labels_confusion_matrix).reshape(2,2)\n",
        "  sns.heatmap(cf_matrix, annot=labels_confusion_matrix, fmt='', cmap='Blues')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOFugarM53om"
      },
      "source": [
        "## **LogisticRegression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD6LMYHQnQVV"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l1', 'l2'] \n",
        "c_values = [ 1.0, 100, 300]\n",
        "\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=10)\n",
        "grid = GridSearchCV(estimator = model,         \n",
        "                    param_grid = grid,            \n",
        "                    cv = cv,\n",
        "                    scoring = 'accuracy', \n",
        "                    refit = 'accuracy',\n",
        "                    n_jobs=-1,\n",
        "                    verbose=10)\n",
        "grid.fit(x_treino,y_treino).best_params_\n",
        "pd.DataFrame(grid.cv_results_)[['params', \n",
        "'mean_test_score',\n",
        "'std_test_score',]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OFhhVZL4Qhe"
      },
      "source": [
        "predict = grid.predict(x_teste)\n",
        "accuracy_score(y_teste, predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ehXrgfn9tTH"
      },
      "source": [
        "confusion_matrix_plot(confusion_matrix(y_teste, predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HypF6Fdh6E8R"
      },
      "source": [
        "## **RandomForestClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eph-FGBtyiKK"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "n_estimators = [100, 1000]\n",
        "max_features = ['sqrt', 'log2']\n",
        "\n",
        "grid = dict(n_estimators=n_estimators,max_features=max_features)\n",
        "cv = StratifiedKFold(n_splits=10)\n",
        "grid = GridSearchCV(estimator = model,         \n",
        "                    param_grid = grid,            \n",
        "                    cv = cv,\n",
        "                    scoring = 'accuracy', \n",
        "                    refit = 'accuracy',\n",
        "                    n_jobs=-1,\n",
        "                    verbose=10)\n",
        "grid.fit(x_treino,y_treino).best_params_\n",
        "pd.DataFrame(grid.cv_results_)[['params', \n",
        "'mean_test_score',\n",
        "'std_test_score',]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmpeTxzh6uZT"
      },
      "source": [
        "predict = grid.predict(x_teste)\n",
        "accuracy_score(y_teste, predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XY2y5RWL2De"
      },
      "source": [
        "confusion_matrix_plot(confusion_matrix(y_teste, predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vK8m8Cm6ODZ"
      },
      "source": [
        "## **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFArZPInxGAb"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "\n",
        "model = SVC()\n",
        "kernel = ['linear','rbf',]\n",
        "C = [100, 300]\n",
        "\n",
        "\n",
        "grid = dict(kernel=kernel,C=C)\n",
        "cv = StratifiedKFold(n_splits=10)\n",
        "grid = GridSearchCV(estimator = model,         \n",
        "                    param_grid = grid,            \n",
        "                    cv = cv,\n",
        "                    scoring = 'accuracy', \n",
        "                    refit = 'accuracy',\n",
        "                    n_jobs=-1,\n",
        "                    verbose=100)\n",
        "grid.fit(x_treino_2,y_treino_2).best_params_\n",
        "pd.DataFrame(grid.cv_results_)[['params', \n",
        "'mean_test_score',\n",
        "'std_test_score',]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw_x2q0E6wYN"
      },
      "source": [
        "predict = grid.predict(x_teste)\n",
        "accuracy_score(y_teste, predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GPA3IQLL3nJ"
      },
      "source": [
        "confusion_matrix_plot(confusion_matrix(y_teste, predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPZLmgiu6XrM"
      },
      "source": [
        "## **MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ-eH6fQzW6r"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "model = MLPClassifier()\n",
        "grid = {\n",
        "    'hidden_layer_sizes': [(10,30,10),(20,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'alpha': [0.05],\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=10)\n",
        "grid = GridSearchCV(estimator = model,         \n",
        "                    param_grid = grid,            \n",
        "                    cv = cv,\n",
        "                    scoring = 'accuracy', \n",
        "                    refit = 'accuracy',\n",
        "                    n_jobs=-1,\n",
        "                    verbose=10)\n",
        "grid.fit(x_treino,y_treino).best_params_\n",
        "pd.DataFrame(grid.cv_results_)[['params', \n",
        "'mean_test_score',\n",
        "'std_test_score',]]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrhN9dsL6xsq"
      },
      "source": [
        "predict = grid.predict(x_teste)\n",
        "accuracy_score(y_teste, predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKj4-KGoL4pL"
      },
      "source": [
        "confusion_matrix_plot(confusion_matrix(y_teste, predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6s9L0_K6Zkv"
      },
      "source": [
        "## **Naives Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNoOv474b9y7"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "model = GaussianNB()\n",
        "grid =  {'var_smoothing': np.logspace(0,-9, num=10)}\n",
        "cv = StratifiedKFold(n_splits=10)\n",
        "grid = GridSearchCV(estimator = model,         \n",
        "                    param_grid = grid,            \n",
        "                    cv = cv,\n",
        "                    scoring = 'accuracy', \n",
        "                    refit = 'accuracy',\n",
        "                    n_jobs=1,\n",
        "                    verbose=10)\n",
        "grid.fit(x_treino.todense(),y_treino).best_params_\n",
        "pd.DataFrame(grid.cv_results_)[['params', \n",
        "'mean_test_score',\n",
        "'std_test_score',]]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ICaAiWW6yxn"
      },
      "source": [
        "predict = grid.predict(x_teste.todense())\n",
        "accuracy_score(y_teste, predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noU0XtD6L5or"
      },
      "source": [
        "confusion_matrix_plot(confusion_matrix(y_teste, predict))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}